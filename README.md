# Persona-Tales

An AI-powered story generation platform with text-to-speech capabilities. Generate personalized stories across multiple genres and listen to them with AI-narrated voice.

## Features

- ğŸ¤– **AI Story Generation** - Powered by fine-tuned Llama 3 model for creative storytelling
- ğŸ­ **Multiple Genres** - Support for various story genres (Fantasy, Sci-Fi, Mystery, Mythology, etc.)
- ğŸ™ï¸ **Text-to-Speech** - Convert generated stories to audio with voice cloning capabilities (CPU-optimized)
- ğŸ‘¤ **User Authentication** - Secure signup/login system with JWT
- ğŸ“Š **User Dashboard** - Track your story statistics and history
- ğŸ† **Achievement System** - Earn badges and certificates based on your activity
- ğŸ’¾ **Story Management** - Save, view, and manage your generated stories
- â˜ï¸ **Cloud Storage** - Audio files stored on Cloudinary

## Screenshots

<div align="center">

### Landing Page

![Landing Page](docs/screenshots/img1.jpeg)

### Story Generation Interface

![Story Generation](docs/screenshots/img2.jpeg)

### User Dashboard

![Dashboard](docs/screenshots/img3.jpeg)

### Audio Playback & Voice Cloning

![Audio Features](docs/screenshots/img4.jpeg)

### Achievements & Badges

![Achievements](docs/screenshots/img5.jpeg)

</div>

## Tech Stack

### Frontend

- React with Vite
- Redux Toolkit for state management
- React Router for navigation
- Axios for API calls
- React Hot Toast for notifications

### Backend

- Node.js with Express
- MongoDB for database
- JWT authentication
- Cloudinary integration

### AI Services (Python)

- **Story Generation**: FastAPI with Fine-tuned Llama 3 8B (GPU)
- **Text-to-Speech**: FastAPI with Coqui XTTS-v2 (CPU-only)
- PyTorch (Hybrid setup: GPU for Story, CPU for TTS)
- PEFT for model adapters

## Prerequisites

### Software

- **Node.js** v16 or higher
- **Python 3.11** (Required for TTS - NOT 3.12 or 3.10)
- **MongoDB** (local or cloud instance)
- **Git**

### Hardware

- **GPU**: CUDA-capable with 6GB+ VRAM (for Story Generation)
- **RAM**: 4-8GB free (for TTS on CPU)
- **Storage**: ~10GB free disk space

### Windows-Specific

- **Microsoft C++ Build Tools** (required for TTS installation)
  - Download: https://visualstudio.microsoft.com/visual-cpp-build-tools/
  - Select: "Desktop development with C++"

### Accounts

- **Cloudinary** account (free tier works)
- **Hugging Face** account with Llama 3 access
  - Request access: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct

## Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd Persona-Tales
```

### 2. Download Pre-trained Model Adapters

Download the fine-tuned model tensors from [this Drive link](https://drive.google.com/drive/folders/11HTh5XXTWYz8b8UIVqHroasoZ13Wxode?usp=sharing).

**Extract to:**

```
server/story_tts_service/story_api_service/llama3_best_adapter/
```

**Should contain:**

- `adapter_config.json`
- `adapter_model.safetensors`
- Other checkpoint files

### 3. Setup Client (Frontend)

```bash
cd client
npm install
```

**Create `.env`:**

```env
VITE_APP_BACKEND_URL=http://localhost:4000/api/v1
```

### 4. Setup Server (Backend)

```bash
cd ../server
npm install
```

**Create `.env`:**

```env
PORT=4000
MONGODB_URL=mongodb://localhost:27017/ai-story-generator
JWT_SECRET=your_jwt_secret_key_here
CLOUD_NAME=your_cloudinary_cloud_name
API_KEY=your_cloudinary_api_key
API_SECRET=your_cloudinary_api_secret
FOLDER_NAME="YourFolderName"

# Python Services URLs
STORY_API_URL=http://localhost:8000
TTS_API_URL=http://localhost:8001
```

**Generate JWT Secret:**

```bash
node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
```

### 5. Setup Python AI Services

#### A. Story Generation Service (GPU - Port 8000)

```bash
cd server/story_tts_service

# Create virtual environment for Story API
python -m venv venv_story

# Activate
# Windows:
venv_story\Scripts\activate
# Linux/Mac:
source venv_story/bin/activate

# Install dependencies
pip install -r story_api_service/requirements.txt
```

**Create `.env` in `story_api_service/`:**

```env
HF_TOKEN="your_hugging_face_token"
```

**Get HuggingFace Token:**

1. Sign up at https://huggingface.co/
2. Request Llama 3 access (approval takes ~1 day)
3. Create token: https://huggingface.co/settings/tokens

#### B. TTS Service (CPU - Port 8001)

**âš ï¸ Important: Requires Python 3.11 specifically**

```bash
cd server/story_tts_service/tts_cpu_service

# Verify Python 3.11
python --version  # Should show 3.11.x
# If not, install Python 3.11 first

# Create venv with Python 3.11
py -3.11 -m venv venv
# OR: python3.11 -m venv venv

# Activate
# Windows PowerShell:
venv\Scripts\Activate.ps1
# Windows CMD:
venv\Scripts\activate.bat
# Linux/Mac:
source venv/bin/activate

# Install dependencies (takes 5-10 min first time)
pip install -r requirements.txt
```

**Windows Users:** If you see "Microsoft Visual C++ 14.0 required" error, install Build Tools first:
https://visualstudio.microsoft.com/visual-cpp-build-tools/

**Detailed TTS Setup:** See `server/story_tts_service/tts_cpu_service/README.md`

## Running the Application

You need **4 terminals running simultaneously**.

### Terminal 1: Frontend (Port 5173)

```bash
cd client
npm run dev
```

Opens at: `http://localhost:5173`

### Terminal 2: Backend (Port 4000)

```bash
cd server
npm run dev
```

Runs on: `http://localhost:4000`

### Terminal 3: Story Generation API (Port 8000)

```bash
cd server/story_tts_service

# Activate story venv
# Windows:
venv_story\Scripts\activate
# Linux/Mac:
source venv_story/bin/activate

cd story_api_service
python model_api.py
```

Runs on: `http://localhost:8000`

**First run:** Downloads Llama 3 model (~10-15GB), takes 10-20 minutes

### Terminal 4: TTS Service (Port 8001)

```bash
cd server/story_tts_service/tts_cpu_service

# Activate TTS venv (Python 3.11)
# Windows:
venv\Scripts\Activate.ps1
# Linux/Mac:
source venv/bin/activate

python tts_server.py
```

Runs on: `http://localhost:8001`

**First run:** Downloads XTTS model (~2GB), takes 2-5 minutes

## Usage

1. Open browser: `http://localhost:5173`
2. Sign up for a new account or log in
3. Enter a story prompt with your desired genre
4. Click generate to create your story
5. Listen to the AI-narrated version
6. Save your favorite stories
7. Track progress and earn achievements

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Persona-Tales                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Frontend (5173)  â†’  Backend (4000)               â”‚
â”‚  React + Vite         Node.js + Express           â”‚
â”‚                       â†“              â†“            â”‚
â”‚                   MongoDB    Python Services      â”‚
â”‚                                â†“           â†“      â”‚
â”‚                         Story API    TTS API      â”‚
â”‚                         (Port 8000)  (Port 8001)  â”‚
â”‚                         GPU: 6-8GB   CPU-only     â”‚
â”‚                         Llama 3      Coqui XTTS   â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
Persona-Tales/
â”œâ”€â”€ ğŸ“„ README.md                        # Main project documentation
â”œâ”€â”€ ğŸ“„ SETUP_CHECKLIST.md               # Step-by-step setup verification
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                            # Documentation & Assets
â”‚   â”œâ”€â”€ screenshots/                    # Application screenshots
â”‚   â”‚   â”œâ”€â”€ img1.jpeg                  # Landing page
â”‚   â”‚   â”œâ”€â”€ img2.jpeg                  # Story generation interface
â”‚   â”‚   â”œâ”€â”€ img3.jpeg                  # User dashboard
â”‚   â”‚   â”œâ”€â”€ img4.jpeg                  # Audio playback & voice cloning
â”‚   â”‚   â””â”€â”€ img5.jpeg                  # Achievements & badges
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md           # Detailed project navigation guide
â”‚
â”œâ”€â”€ ğŸ“‚ experiments/                     # Model Selection Experiments
â”‚   â”œâ”€â”€ DistilGPT_2.ipynb              # DistilGPT-2 fine-tuning experiment
â”‚   â”œâ”€â”€ Meta_Llama.ipynb               # Llama 3 8B fine-tuning experiment
â”‚   â””â”€â”€ README.md                      # Comparative analysis & methodology
â”‚
â”œâ”€â”€ ğŸ“‚ client/                          # React Frontend (Port 5173)
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ demo-audio/                # Demo story audio files
â”‚   â”‚   â”‚   â”œâ”€â”€ story1.mp3
â”‚   â”‚   â”‚   â”œâ”€â”€ story2.mp3
â”‚   â”‚   â”‚   â””â”€â”€ story3.mp3
â”‚   â”‚   â””â”€â”€ vite.svg
â”‚   â”‚
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”‚   â””â”€â”€ badges/                # Achievement badge SVGs
â”‚   â”‚   â”‚       â”œâ”€â”€ beginner.svg
â”‚   â”‚   â”‚       â”œâ”€â”€ enthusiast.svg
â”‚   â”‚   â”‚       â””â”€â”€ master.svg
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ common/                # Shared components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.jsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ OpenRoute.jsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ PrivateRoute.jsx
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ core/                  # Core UI components
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ProfileDropdown.jsx
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ landing/               # Landing page components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LandingNavbar.jsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ HeroSection.jsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ GenreHighlights.jsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ HowItWorks.jsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ WhatMakesUsSpecial.jsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Footer.jsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ PromptInputSection.jsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ landing.css
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx          # Main dashboard component
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioCloneSection.jsx  # Voice cloning interface
â”‚   â”‚   â”‚   â”œâ”€â”€ GeneratedStoryDisplay.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProfileCard.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ StoryStatistics.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ RecentStories.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Certificates.jsx       # Achievement certificates
â”‚   â”‚   â”‚   â”œâ”€â”€ Certificates.css
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.jsx
â”‚   â”‚   â”‚   â””â”€â”€ MotivationalBanner.jsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ LandingPage.jsx        # Public landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx               # Authenticated home
â”‚   â”‚   â”‚   â”œâ”€â”€ DemoPage.jsx           # Demo functionality
â”‚   â”‚   â”‚   â”œâ”€â”€ Login.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Signup.jsx
â”‚   â”‚   â”‚   â””â”€â”€ ErrorPage.jsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ apiConnector.js        # Axios configuration
â”‚   â”‚   â”‚   â””â”€â”€ operations/
â”‚   â”‚   â”‚       â”œâ”€â”€ authAPI.js         # Authentication APIs
â”‚   â”‚   â”‚       â””â”€â”€ storyAPI.js        # Story generation APIs
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ slices/                    # Redux state slices
â”‚   â”‚   â”‚   â”œâ”€â”€ authSlice.js
â”‚   â”‚   â”‚   â””â”€â”€ profileSlice.js
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useOnClickOutside.js
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â””â”€â”€ demoData.js            # Demo story data
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ constants.js
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ reducer/
â”‚   â”‚   â”‚   â””â”€â”€ index.js               # Root reducer
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ App.jsx                    # Main app component
â”‚   â”‚   â”œâ”€â”€ main.jsx                   # Entry point
â”‚   â”‚   â””â”€â”€ index.css                  # Global styles
â”‚   â”‚
â”‚   â”œâ”€â”€ .env                           # Frontend environment variables
â”‚   â”œâ”€â”€ ENV_TEMPLATE.txt               # Environment template
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js                 # Vite configuration
â”‚   â”œâ”€â”€ eslint.config.js
â”‚   â””â”€â”€ index.html
â”‚
â””â”€â”€ ğŸ“‚ server/                          # Express Backend (Port 4000)
    â”œâ”€â”€ config/
    â”‚   â”œâ”€â”€ database.js                # MongoDB connection
    â”‚   â””â”€â”€ cloudinary.js              # Cloudinary configuration
    â”‚
    â”œâ”€â”€ controllers/
    â”‚   â”œâ”€â”€ Auth.js                    # Authentication logic
    â”‚   â””â”€â”€ Story.js                   # Story CRUD operations
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ User.js                    # User schema
    â”‚   â””â”€â”€ Story.js                   # Story schema
    â”‚
    â”œâ”€â”€ routes/
    â”‚   â”œâ”€â”€ User.js                    # User routes
    â”‚   â””â”€â”€ Story.js                   # Story routes
    â”‚
    â”œâ”€â”€ middlewares/
    â”‚   â””â”€â”€ auth.js                    # JWT verification
    â”‚
    â”œâ”€â”€ utils/
    â”‚   â””â”€â”€ fileUploader.js            # Cloudinary upload helper
    â”‚
    â”œâ”€â”€ story_tts_service/             # Python AI Services
    â”‚   â”‚
    â”‚   â”œâ”€â”€ story_api_service/         # Story Generation API (Port 8000)
    â”‚   â”‚   â”œâ”€â”€ llama3_best_adapter/   # Fine-tuned LoRA adapters
    â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_config.json
    â”‚   â”‚   â”‚   â”œâ”€â”€ adapter_model.safetensors
    â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoint-203/    # Training checkpoints
    â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoint-406/
    â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoint-609/
    â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoint-812/
    â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoint-1015/   # Best checkpoint
    â”‚   â”‚   â”‚   â””â”€â”€ runs/              # TensorBoard logs
    â”‚   â”‚   â”‚
    â”‚   â”‚   â”œâ”€â”€ venv/                  # Python virtual environment
    â”‚   â”‚   â”œâ”€â”€ model_api.py           # FastAPI server
    â”‚   â”‚   â”œâ”€â”€ .env                   # HuggingFace token
    â”‚   â”‚   â””â”€â”€ ENV_TEMPLATE.txt
    â”‚   â”‚
    â”‚   â”œâ”€â”€ tts_cpu_service/           # Text-to-Speech API (Port 8001)
    â”‚   â”‚   â”œâ”€â”€ venv/                  # Python 3.11 virtual environment
    â”‚   â”‚   â”œâ”€â”€ tts_server.py          # FastAPI TTS server
    â”‚   â”‚   â”œâ”€â”€ requirements.txt       # TTS dependencies
    â”‚   â”‚   â”œâ”€â”€ sample_voice.wav       # Sample voice file
    â”‚   â”‚   â”œâ”€â”€ Recording.wav          # User recordings
    â”‚   â”‚   â”œâ”€â”€ result.wav             # Generated audio output
    â”‚   â”‚   â”œâ”€â”€ README.md              # TTS setup guide
    â”‚   â”‚   â””â”€â”€ NODEJS_INTEGRATION.md  # Node.js integration docs
    â”‚   â”‚
    â”‚   â””â”€â”€ requirements.txt           # Shared Python dependencies
    â”‚
    â”œâ”€â”€ .env                           # Backend environment variables
    â”œâ”€â”€ ENV_TEMPLATE.txt               # Environment template
    â”œâ”€â”€ package.json
    â”œâ”€â”€ index.js                       # Express server entry point
    â””â”€â”€ README.md                      # Server documentation
```

### Key Directories Explained

**ğŸ“‚ docs/** - Contains all project documentation and visual assets

**ğŸ“‚ experiments/** - Jupyter notebooks documenting the model selection process (DistilGPT-2 vs Llama 3)

**ğŸ“‚ client/** - React-based frontend with Redux state management, serving the user interface

**ğŸ“‚ server/** - Node.js backend handling authentication, database operations, and orchestrating AI services

**ğŸ“‚ story_api_service/** - Python FastAPI service running fine-tuned Llama 3 8B on GPU for story generation

**ğŸ“‚ tts_cpu_service/** - Python FastAPI service running Coqui XTTS-v2 on CPU for text-to-speech with voice cloning

**ğŸ“‚ llama3_best_adapter/** - QLoRA adapters containing the fine-tuned weights for our story generation model

## Environment Variables

### Client `.env`

```env
VITE_APP_BACKEND_URL=http://localhost:4000/api/v1
```

### Server `.env`

```env
PORT=4000
MONGODB_URL=mongodb://localhost:27017/ai-story-generator
JWT_SECRET=<generate-random-string>
CLOUD_NAME=<cloudinary-cloud-name>
API_KEY=<cloudinary-api-key>
API_SECRET=<cloudinary-api-secret>
FOLDER_NAME="YourFolderName"
STORY_API_URL=http://localhost:8000
TTS_API_URL=http://localhost:8001
```

### Story API `.env`

```env
HF_TOKEN="your_hugging_face_token"
```

### TTS Service

No `.env` needed - configured in code

## Troubleshooting

### MongoDB Connection Error

- Ensure MongoDB is running: `mongod` or `net start MongoDB`
- Check connection string in `server/.env`
- Verify port 27017 is not blocked

### GPU Memory Issues (Story API)

- Close other GPU applications
- Check VRAM usage: `nvidia-smi`
- Ensure TTS is using CPU (not GPU)
- Model uses 4-bit quantization (~6-8GB VRAM)

### Python Version Issues (TTS)

- **Critical:** TTS requires Python 3.11 (NOT 3.12)
- Check: `python --version` or `py --list`
- Install 3.11: https://www.python.org/downloads/release/python-31110/
- Use: `py -3.11 -m venv venv`

### Microsoft Visual C++ Error (Windows, TTS)

- Install C++ Build Tools
- Download: https://visualstudio.microsoft.com/visual-cpp-build-tools/
- Select: "Desktop development with C++"
- Restart computer, then reinstall: `pip install -r requirements.txt`

### Port Conflicts

```bash
# Check which ports are in use
netstat -ano | findstr "4000 5173 8000 8001"

# Kill process if needed
taskkill /PID <pid> /F
```

### Hugging Face Token Error

- Ensure you requested Llama 3 access (takes ~1 day for approval)
- Verify token has read permissions
- Check token: https://huggingface.co/settings/tokens

### TTS Model Not Loading

- Wait longer on first run (~2-5 min download)
- Check internet connection
- Verify 2GB+ free disk space
- Check logs for download progress

## Testing

### Quick Test All Services

**Frontend:**

```bash
http://localhost:5173
```

Should load the React app

**Backend:**

```bash
curl http://localhost:4000/api/v1/health
```

**Story API:**

```bash
curl -X POST http://localhost:8000/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt":"test"}'
```

**TTS API:**

```bash
curl.exe http://localhost:8001/health
```

## Development

### Starting Fresh

1. Pull latest code: `git pull`
2. Update dependencies:
   - Frontend: `cd client && npm install`
   - Backend: `cd server && npm install`
   - Python services: `pip install -r requirements.txt`

### Monitoring Resources

- **GPU (Story):** `nvidia-smi` - Should use 6-8GB
- **CPU (TTS):** Task Manager - Should use 80-100% during generation
- **Ports:** All 4 services must run simultaneously

## Documentation

- **Complete Setup Checklist:** `SETUP_CHECKLIST.md`
- **Model Selection Experiments:** `experiments/README.md`
- **Environment Templates:**
  - `client/ENV_TEMPLATE.txt`
  - `server/ENV_TEMPLATE.txt`
  - `server/story_tts_service/story_api_service/ENV_TEMPLATE.txt`

---

## Research & Technical Foundation

This project is built upon cutting-edge research in language models, quantization, and speech synthesis.

### Core Research Papers

#### 1. QLoRA: Efficient Finetuning of Quantized LLMs

**Citation:** Dettmers, T., et al. (2023). _QLoRA: Efficient Finetuning of Quantized LLMs_. [arXiv:2305.14314](https://arxiv.org/abs/2305.14314)

**Use in Project:**

- Enabled fine-tuning Llama 3 8B on consumer GPU (RTX 4060 10GB)
- 4-bit quantization reduced VRAM usage from ~16GB to ~6GB
- Maintained model quality while making large language models accessible
- Core technique for our Story Generation API

**Impact:** Without QLoRA, we would need expensive cloud GPUs or be limited to much smaller models with inferior storytelling capabilities.

#### 2. Better Speech Synthesis through Scaling (Tortoise TTS)

**Citation:** Betker, J. (2023). _Better Speech Synthesis through Scaling_. [arXiv:2305.07243](https://arxiv.org/abs/2305.07243)

**Use in Project:**

- Foundational architecture for Coqui XTTS-v2 (our TTS engine)
- Autoregressive transformer treats audio generation like text generation
- Enables zero-shot voice cloning from short audio samples
- Powers our Text-to-Speech API with voice personalization

**Impact:** This architecture breakthrough allows users to clone voices using just 6-10 seconds of audio, making personalized narration accessible to everyone.

#### 3. TinyStories: How Small Can Language Models Be?

**Citation:** Eldan, R., & Li, Y. (2023). _TinyStories: How Small Can Language Models Be and Still Speak Coherent English?_ [arXiv:2305.07759](https://arxiv.org/abs/2305.07759)

**Use in Project:**

- Validated our dataset curation strategy
- Proved domain-specific fine-tuning works with smaller, high-quality datasets
- Inspired our approach: fine-tune powerful model on 100 curated children's stories
- Demonstrated that constrained vocabulary enhances coherence for target audience

**Impact:** This research justified using a curated dataset of 100 stories instead of massive web-scraped data, resulting in better quality and faster training.

### Additional References

- **PEFT (Parameter-Efficient Fine-Tuning):** [Hugging Face PEFT Library](https://github.com/huggingface/peft)
- **Llama 3 Model:** [Meta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)
- **Coqui TTS:** [XTTS-v2 Documentation](https://docs.coqui.ai/)

---

## Dataset

### Training Data

Our story generation model was fine-tuned on a custom-curated dataset of 100 high-quality children's stories.

**ğŸ“Š Dataset Link:** [View Dataset on Google Sheets](https://docs.google.com/spreadsheets/d/1fG7maZYAvMdhCTcasCjEYDaH6UMz8NrB0MaCbRq37dQ/edit?usp=sharing)

**Dataset Composition:**

- **Total Stories:** 1000
- **Genres:** Adventure & Exploration, Fantasy, Mystery, Mythology, Sci-Fi
- **Format:** Structured with Prompt, Characters, Genre, and Story fields
- **Average Length:** 150-300 words per story
- **Target Audience:** Children (ages 6-12)

**Data Split:**

- Training: 81 stories (81%)
- Validation: 9 stories (9%)
- Test: 10 stories (10%)

**Curation Principles:**

- Age-appropriate content and vocabulary
- Diverse character representations
- Clear narrative structure (beginning, middle, end)
- Positive themes and educational value
- Grammatically correct and well-written

**Quality Control:**

- Manual review of all stories
- Consistency in formatting
- Balanced genre distribution
- Culturally sensitive content

This carefully curated approach, inspired by the [TinyStories paper](https://arxiv.org/abs/2305.07759), proved more effective than using large, noisy web-scraped datasets.

---

## Model Selection & Experiments

We conducted rigorous experiments to select the optimal model architecture for story generation. The complete analysis is available in the `experiments/` folder.

### Compared Models

1. **DistilGPT-2** (82M parameters)

   - âœ… Fast inference, low memory
   - âŒ Poor coherence, repetitive output

2. **Meta Llama 3 8B Instruct** (8B parameters)
   - âœ… Excellent storytelling quality
   - âœ… Strong genre adherence
   - âœ… Creative and coherent narratives
   - âš ï¸ Higher computational requirements

**Winner:** Meta Llama 3 8B Instruct

**Rationale:** The dramatic improvement in story quality justified the additional computational requirements. With QLoRA optimization, we made it feasible on consumer hardware.

**ğŸ“– Detailed Analysis:** See `experiments/README.md` for comprehensive comparison, metrics, and methodology.

---

## Future Scope & Enhancements

### Short-Term Goals (Next 3-6 months)

1. **Model Optimization**

   - Implement speculative decoding for 2-3x faster inference
   - Explore smaller Llama variants (1B-3B) for reduced latency
   - Test quantization to 3-bit or 2-bit for even lower VRAM usage

2. **Feature Enhancements**

   - Multi-language story generation (Hindi, Spanish, French)
   - Illustration generation using Stable Diffusion
   - Interactive storytelling with user choices
   - Story continuation and character memory

3. **User Experience**
   - Mobile app (React Native)
   - Offline mode with cached stories
   - Social features (share stories, like, comment)
   - Parental controls and content filtering

### Medium-Term Goals (6-12 months)

4. **Model Distillation**

   - Distill fine-tuned Llama 3 into 1B parameter SLM (Small Language Model)
   - Target: Run entirely on smartphone CPU without server
   - Maintain 80%+ quality with 10x faster inference

5. **Advanced TTS**

   - Implement non-autoregressive TTS for faster generation
   - Multi-speaker support within single story
   - Emotional speech synthesis (happy, sad, excited voices)
   - Background music and sound effects integration

6. **Educational Features**
   - Reading comprehension quizzes
   - Vocabulary building exercises
   - Story-based learning modules
   - Teacher dashboard for classroom use

### Long-Term Vision (1-2 years)

7. **Multimodal Storytelling**

   - Video generation from stories
   - Animated character creation
   - VR/AR story experiences
   - Interactive story games

8. **AI Personalization**

   - Learning from user preferences
   - Adaptive difficulty levels
   - Personalized story recommendations
   - Character consistency across stories

9. **Platform Expansion**
   - API for third-party integrations
   - White-label solution for schools
   - Publisher partnerships
   - Content creator marketplace

### Research Directions

10. **Novel Architectures**

    - Explore emerging models (Phi-3, Gemma-2, Mistral)
    - Test mixture-of-experts (MoE) models
    - Investigate retrieval-augmented generation (RAG)
    - Experiment with flow matching for faster TTS

11. **Efficiency Techniques**
    - GPTQ or AWQ quantization for edge deployment
    - CPU offloading for larger models
    - Model pruning and compression
    - Hybrid cloud-edge inference

---

## Contributors

This project was developed by:

- **[Anshul Kansal](https://github.com/anshulkansal04)**
- **[Lov Kumar Kumawat](https://github.com/Lovkumawat)**
- **[Vishwas Mishra](https://github.com/CyberMage7)**
- **[Satwik Pandey](https://github.com/worldisconfusion)**

## License

(Add your license here)

---

**Need Help?**

1. Check `SETUP_CHECKLIST.md` for step-by-step verification
2. Review service-specific READMEs
3. Verify all environment variables are set
4. Check that all 4 services are running
5. Review troubleshooting sections above
